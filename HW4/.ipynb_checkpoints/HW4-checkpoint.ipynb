{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Erin Witmer \n",
    "CSC 440"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [8.3] Given a decision tree, you have the option of (a) converting the decision tree to rules and then pruning the resulting rules, or (b) pruning the decision tree and then converting the pruned tree into rules. What advantage does (a) have over (b)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A decision tree can be converted to IF-THEN rules by tracing the path from the root node to each leaf in the tree. If the tree is pruned before the rules are created, as is suggested in case (b), then any path dependent on the trimmed node will also be trimmed. First creating the rules, and then trimming them as proposed in (a) allows for more precision when trimming. Leaves dependent on a specific preceding node may be trimmed, while other leaves dependent on that same preceding node may be kept. However, it is important to note the higher computational complexity associated with building a full tree, converting to rules and then trimming. Regardless, method (a) generally generates a more precise and accurate set of rules and is worth the computational cost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](tree.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [8.5] Given a 5-GB data set with 50 attributes (each containing 100 distinct values) and 512 MB of main memory in your laptop, outline an efficient method that constructs decision trees in such large data sets. Justify your answer by rough calculation of your main memory usage. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The use of the RainForest algorithm would be most effective in this case. RainForest adapts to the amount of main memory available and applies to any decision tree induction algorithm. The first step is to construct an AVC-set for each attribute. If the total data set is 5MB, on average each attribute would be 100MB. The process would be to extract one attribute, calculate the AVC, and store that set in main memory. On average, if you assume you are storing the value/class count as an integer (4 bytes), there are 100 values per attribute, and assume there are 2 class outcomes, an individual AVC set would require approximate (100 x 2 x 4 bytes) = 800 bytes. So the data holding the aggregate information from which the decision tree can be constructed is only 40 KB. Since this is the aggregate data, every level of the tree will be some derivative of this data. Utilizing the basic algorithm for inducing a decision tree, you could loop through many times without running out of memory. If the tree got very deep and space was an issue, tree prunning could take place while the tree is being generated and only summary information could be retained at each level. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [8.7] The following table consists of training data from an employee database. The data have been generalized.... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'t0': ['sales', 'senior', '31…35', '46K…50K', 30],\n",
    "        't1': ['sales', 'junior', '26…30', '26K…30K', 40],\n",
    "        't2': ['sales', 'junior', '31…35', '31K…35K', 40],\n",
    "        't3': ['systems', 'junior', '21…25', '46K…50K', 20],\n",
    "        't4': ['systems', 'senior', '31…35', '66K…70K', 5],\n",
    "        't5': ['systems', 'junior', '26…30', '46K…50K', 3],\n",
    "        't6': ['systems', 'senior', '41…45', '66K…70K', 3],\n",
    "        't7': ['marketing', 'senior', '36…40', '46K…50K', 10],\n",
    "        't8': ['marketing', 'junior', '31…35', '41K…45K', 4],\n",
    "        't9': ['secretary', 'senior', '46…50', '36K…40K', 4],\n",
    "        't10': ['secretary', 'junior', '26…30', '26K…30K', 6]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a.) How would you modify the basic decision tree algorithm to take into consideration the count of each generalized data tuple? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The relative weights of each of the tuples in the entropy calculation needs to be adjusted to reflect the proportion of the count to total employees (sum of count). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b.) Use your algorithm to construct a decision tree from the given data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        count\n",
      "class        \n",
      "junior    113\n",
      "senior     52\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "from functools import reduce\n",
    "\n",
    "def entropy(a,b):\n",
    "    sum = a+b\n",
    "    total = -(a/sum)*math.log2((a/sum))-(b/sum)*math.log2((b/sum))\n",
    "    return total\n",
    "\n",
    "df = pd.DataFrame.from_dict(data, orient='index', columns=['dept', 'class', 'age', 'salary', 'count'])\n",
    "class_count = df.groupby('class').sum()\n",
    "print(class_count)\n",
    "head = entropy(113,52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           count\n",
      "dept            \n",
      "marketing     14\n",
      "sales        110\n",
      "secretary     10\n",
      "systems       31\n"
     ]
    }
   ],
   "source": [
    "# department\n",
    "dept_count = df.groupby(['dept']).sum()\n",
    "print(dept_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  count\n",
      "dept      class        \n",
      "marketing junior      4\n",
      "          senior     10\n",
      "sales     junior     80\n",
      "          senior     30\n",
      "secretary junior      6\n",
      "          senior      4\n",
      "systems   junior     23\n",
      "          senior      8\n"
     ]
    }
   ],
   "source": [
    "sales = 110/165 \n",
    "systems = 31/165\n",
    "marketing = 14/165\n",
    "secretary = 10/165\n",
    "\n",
    "dept_outcome = df.groupby(['dept','class']).sum()\n",
    "print(dept_outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.048606785991983426\n"
     ]
    }
   ],
   "source": [
    "dept_gain = head - (sales*entropy(80,30)\n",
    "                    +systems*entropy(23,8)\n",
    "                    +marketing*entropy(4,10)\n",
    "                    +secretary*entropy(6,4))\n",
    "print(dept_gain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       count\n",
      "age         \n",
      "21…25     20\n",
      "26…30     49\n",
      "31…35     79\n",
      "36…40     10\n",
      "41…45      3\n",
      "46…50      4\n"
     ]
    }
   ],
   "source": [
    "# age\n",
    "age_count = df.groupby(['age']).sum()\n",
    "print(age_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              count\n",
      "age   class        \n",
      "21…25 junior     20\n",
      "26…30 junior     49\n",
      "31…35 junior     44\n",
      "      senior     35\n",
      "36…40 senior     10\n",
      "41…45 senior      3\n",
      "46…50 senior      4\n"
     ]
    }
   ],
   "source": [
    "early20=20/165\n",
    "late20=49/165\n",
    "early30=79/165\n",
    "late30=10/165\n",
    "early40=3/165\n",
    "late40=4/165\n",
    "\n",
    "age_outcome = df.groupby(['age','class']).sum()\n",
    "print(age_outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4247351209783661\n"
     ]
    }
   ],
   "source": [
    "age_gain = head - (early30*entropy(44,35))\n",
    "print(age_gain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         count\n",
      "salary        \n",
      "26K…30K     46\n",
      "31K…35K     40\n",
      "36K…40K      4\n",
      "41K…45K      4\n",
      "46K…50K     63\n",
      "66K…70K      8\n"
     ]
    }
   ],
   "source": [
    "# salary\n",
    "salary_count = df.groupby(['salary']).sum()\n",
    "print(salary_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                count\n",
      "salary  class        \n",
      "26K…30K junior     46\n",
      "31K…35K junior     40\n",
      "36K…40K senior      4\n",
      "41K…45K junior      4\n",
      "46K…50K junior     23\n",
      "        senior     40\n",
      "66K…70K senior      8\n"
     ]
    }
   ],
   "source": [
    "high20=46/165\n",
    "low30=40/165\n",
    "high30=4/165\n",
    "low40=4/165\n",
    "high40=63/165\n",
    "high60=8/165\n",
    "\n",
    "salary_outcome = df.groupby(['salary','class']).sum()\n",
    "print(salary_outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5375181264158646\n"
     ]
    }
   ],
   "source": [
    "salary_gain = head - (high40*entropy(23,40))\n",
    "print(salary_gain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      count\n",
      "salary  age   class        \n",
      "26K…30K 26…30 junior     46\n",
      "31K…35K 31…35 junior     40\n",
      "36K…40K 46…50 senior      4\n",
      "41K…45K 31…35 junior      4\n",
      "46K…50K 21…25 junior     20\n",
      "        26…30 junior      3\n",
      "        31…35 senior     30\n",
      "        36…40 senior     10\n",
      "66K…70K 31…35 senior      5\n",
      "        41…45 senior      3\n"
     ]
    }
   ],
   "source": [
    "# The first level of the decision tree is by salary\n",
    "salary_age = df.groupby(['salary','age','class']).sum()\n",
    "print(salary_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          count\n",
      "salary  dept      class        \n",
      "26K…30K sales     junior     40\n",
      "        secretary junior      6\n",
      "31K…35K sales     junior     40\n",
      "36K…40K secretary senior      4\n",
      "41K…45K marketing junior      4\n",
      "46K…50K marketing senior     10\n",
      "        sales     senior     30\n",
      "        systems   junior     23\n",
      "66K…70K systems   senior      8\n"
     ]
    }
   ],
   "source": [
    "salary_dept = df.groupby(['salary','dept','class']).sum()\n",
    "print(salary_dept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first level of the decision tree is a split by salary, because the information gain is the highest based on that split. There is only one ambiguous category after the salary split (46k...50k), and a further split based on either age (21...25 -> junior, 26...30 -> junior, 31...35 -> senior, 36...40 -> senior) or department (marketing -> senior, sales -> senior, systems -> junior) will result in a pure split of the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c.) Given a data tuple having the values “systems,” “26...30,” and “46–50K” for the attributes department, age, and salary, respectively, what would a naive Bayesian classification of the status for the tuple be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0007172314864622557\n",
      "0.012302997078625555\n"
     ]
    }
   ],
   "source": [
    "p_senior = 52/165\n",
    "p_junior = 113/165\n",
    "\n",
    "p_senior_systems = 8/52\n",
    "p_junior_systems = 23/113\n",
    "\n",
    "p_senior_26 = 1/52 # modifier\n",
    "p_junior_26 = 49/113\n",
    "\n",
    "p_senior_46 = 40/52\n",
    "p_junior_46 = 23/113\n",
    "\n",
    "senior = p_senior * p_senior_systems * p_senior_26 * p_senior_46\n",
    "junior = p_junior * p_junior_systems * p_junior_26 * p_junior_46\n",
    "\n",
    "print(senior)\n",
    "print(junior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Bayesian classification would be junior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [8.12] The data tuples of Figure 8.25 are sorted by decreasing probability value, as returned by a classifier. For each tuple, compute the values for the number of true positives (TP), false positives (FP), true negatives (TN), and false negatives (FN). Compute the true positive rate (TPR) and false positive rate (FPR). Plot the ROC curve for the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Prob.</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tuple</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P</td>\n",
       "      <td>0.78</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P</td>\n",
       "      <td>0.66</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>N</td>\n",
       "      <td>0.60</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>P</td>\n",
       "      <td>0.55</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>N</td>\n",
       "      <td>0.53</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>N</td>\n",
       "      <td>0.52</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>N</td>\n",
       "      <td>0.51</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>P</td>\n",
       "      <td>0.40</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Class  Prob.  TP  FP  TN  FN  TPR  FPR\n",
       "Tuple                                       \n",
       "1         P   0.95   1   0   5   4  0.2  0.0\n",
       "2         N   0.85   1   1   4   4  0.2  0.2\n",
       "3         P   0.78   2   1   4   3  0.4  0.2\n",
       "4         P   0.66   3   1   4   2  0.6  0.2\n",
       "5         N   0.60   3   2   3   2  0.6  0.4\n",
       "6         P   0.55   4   2   3   1  0.8  0.4\n",
       "7         N   0.53   4   3   2   1  0.8  0.6\n",
       "8         N   0.52   4   4   1   1  0.8  0.8\n",
       "9         N   0.51   4   5   0   1  0.8  1.0\n",
       "10        P   0.40   5   5   0   0  1.0  1.0"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc = pd.read_excel('roc.xlsx', index_col=0, dtype={'TPR': float, 'FPR': float})\n",
    "roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "tpr = roc.iloc[:,6].values\n",
    "fpr = roc.iloc[:,7].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'true positive rate')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(fpr, tpr, 'o', color='black');\n",
    "plt.xlabel('false positive rate')\n",
    "plt.ylabel('true positive rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [8.14] Suppose that we want to select between two prediction models, M1 and M2. We have performed 10 rounds of 10-fold cross-validation on each model, where the same data partitioning in round i is used for both M1 and M2. The error rates obtained for M1 are 30.5, 32.2, 20.7, 20.6, 31.0, 41.0, 27.7, 26.0, 21.5, 26.0. The error rates for M2 are 22.4, 14.5, 22.4, 19.6, 20.7, 20.4, 22.1, 19.4, 16.2, 35.0. Comment on whether one model is significantly better than the other considering a significance level of 1%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "m1 = [30.5, 32.2, 20.7, 20.6, 31.0, 41.0, 27.7, 26.0, 21.5, 26.0]\n",
    "m2 = [22.4, 14.5, 22.4, 19.6, 20.7, 20.4, 22.1, 19.4, 16.2, 35.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4712371600876786"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def var_diff(m1,m2):\n",
    "    total = 0\n",
    "    m1_avg = np.average(m1)\n",
    "    m2_avg = np.average(m2)\n",
    "    k = len(m1)\n",
    "    d = m1_avg - m2_avg\n",
    "    \n",
    "    for i in range(k):\n",
    "        add = (m1[i]-m2[i]-(m1_avg-m2_avg)) ** 2\n",
    "        total += add\n",
    "\n",
    "    total = total / k\n",
    "    return d/np.sqrt(total / k)\n",
    "\n",
    "var_diff(m1,m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-3.2498355440153697, 3.2498355440153697)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import t\n",
    "\n",
    "# two sided t-test with k-1 dof\n",
    "t.interval(0.99, df=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value (2.47) is not greater than 3.25 or less than -3.25, therefore we cannot reject the null hypothesis that one model is significantly better than the other at a significance level of 1%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
