{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Erin Witmer\n",
    "CSC 440"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [10.2] Suppose that the data mining task is to cluster points (with(x,y) representing location) into three clusters, where the points are A1(2,10), A2(2,5), A3(8,4), B1(5,8), B2(7,5), B3(6,4), C1(1,2), C2(4,9). The distance function is Euclidean distance. Suppose initially we assign A1, B1, and C1 as the center of each cluster, respectively. Use the k-means algorithm to show only:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) The three cluster centers after the first round of execution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['a1','a2','a3','b1','b2','b3','c1','c2']\n",
    "x = [2,2,8,5,7,6,1,4]\n",
    "y = [10,5,4,8,5,4,2,9]\n",
    "centers = [[2,10],[5,8],[1,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist(obj1, obj2, l):\n",
    "    total = 0\n",
    "    for i in range(len(obj1)):\n",
    "        total += abs(obj1[i]-obj2[i]) ** l\n",
    "    return total ** (1/l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign(centers, x, y, names):\n",
    "    k = [[],[],[]]\n",
    "    \n",
    "    for i in range(len(names)):\n",
    "        center = 0;\n",
    "        min = 100\n",
    "        for j in range(3):\n",
    "            distance = dist((x[i],y[i]),(centers[j][0],centers[j][1]),2)\n",
    "            if distance < min:\n",
    "                min = distance\n",
    "                center = j\n",
    "        k[center].append(names[i]) \n",
    "            \n",
    "    return k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the first execution, the clusters are: [['a1'], ['a3', 'b1', 'b2', 'b3', 'c2'], ['a2', 'c1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['a1'], ['a3', 'b1', 'b2', 'b3', 'c2'], ['a2', 'c1']]\n"
     ]
    }
   ],
   "source": [
    "cluster_1 = assign(centers,x,y,names)\n",
    "print(cluster_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_means(clusters, x, y, names):\n",
    "    centers = [[],[],[]]\n",
    "    for i in range(len(clusters)):\n",
    "        x_total = 0\n",
    "        y_total = 0\n",
    "        for j in range(len(clusters[i])):\n",
    "            x_total += x[names.index(clusters[i][j])]\n",
    "            y_total += y[names.index(clusters[i][j])]\n",
    "        centers[i] = [x_total/len(clusters[i]),y_total/len(clusters[i])]\n",
    "    return centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.0, 10.0], [6.0, 6.0], [1.5, 3.5]]\n"
     ]
    }
   ],
   "source": [
    "centers_2 = calc_means(cluster_1, x, y, names)\n",
    "print(centers_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the first execution, the centers of the clusters are: [[2.0, 10.0], [6.0, 6.0], [1.5, 3.5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) The final three clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['a1', 'c2'], ['a3', 'b1', 'b2', 'b3'], ['a2', 'c1']]\n"
     ]
    }
   ],
   "source": [
    "cluster_2 = assign(centers_2,x,y,names)\n",
    "print(cluster_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.0, 9.5], [6.5, 5.25], [1.5, 3.5]]\n"
     ]
    }
   ],
   "source": [
    "centers_3 = calc_means(cluster_2, x, y, names)\n",
    "print(centers_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['a1', 'b1', 'c2'], ['a3', 'b2', 'b3'], ['a2', 'c1']]\n"
     ]
    }
   ],
   "source": [
    "cluster_3 = assign(centers_3,x,y,names)\n",
    "print(cluster_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.6666666666666665, 9.0], [7.0, 4.333333333333333], [1.5, 3.5]]\n"
     ]
    }
   ],
   "source": [
    "centers_4 = calc_means(cluster_3, x, y, names)\n",
    "print(centers_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['a1', 'b1', 'c2'], ['a3', 'b2', 'b3'], ['a2', 'c1']]\n"
     ]
    }
   ],
   "source": [
    "cluster_4 = assign(centers_4,x,y,names)\n",
    "print(cluster_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These three clusters represent a local optimal solution: [['a1', 'b1', 'c2'], ['a3', 'b2', 'b3'], ['a2', 'c1']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [10.3] Use an example to show why the k-means algorithm may not find the global optimum, that is, optimizing the within-cluster variation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['a1','a2','a3', 'a4']\n",
    "x = [0,0,4,4]\n",
    "y = [0,2,0,2]\n",
    "centers = [[2,0],[2,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign2(centers, x, y, names):\n",
    "    k = [[],[]]\n",
    "    \n",
    "    for i in range(len(names)):\n",
    "        center = 0;\n",
    "        min = 100\n",
    "        for j in range(2):\n",
    "            distance = dist((x[i],y[i]),(centers[j][0],centers[j][1]),2)\n",
    "            if distance < min:\n",
    "                min = distance\n",
    "                center = j\n",
    "        k[center].append(names[i]) \n",
    "            \n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['a1', 'a3'], ['a2', 'a4']]\n"
     ]
    }
   ],
   "source": [
    "cluster_a = assign2(centers, x, y, names)\n",
    "print(cluster_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_means2(clusters, x, y, names):\n",
    "    centers = [[],[]]\n",
    "    for i in range(len(clusters)):\n",
    "        x_total = 0\n",
    "        y_total = 0\n",
    "        for j in range(len(clusters[i])):\n",
    "            x_total += x[names.index(clusters[i][j])]\n",
    "            y_total += y[names.index(clusters[i][j])]\n",
    "        centers[i] = [x_total/len(clusters[i]),y_total/len(clusters[i])]\n",
    "    return centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.0, 0.0], [2.0, 2.0]]\n"
     ]
    }
   ],
   "source": [
    "centers_a = calc_means2(cluster_a, x, y, names)\n",
    "print(centers_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['a1', 'a3'], ['a2', 'a4']]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assign2(centers_a, x, y, names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The global optimum is [['a1', 'a2'],['a3','a4']] however because of where the initial centers were placed, the local optimum will be reached but the global optimum will not. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [10.6] Both k-means and k-medoids algorithms can perform effective clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Illustrate the strength and weakness of k-means in comparison with the k-medoids algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These distance based methods use iterative relocation techniques to move objects from one partition to another. Both work well finding spherical clusters in small-mid sized databases. K-means partitions objects into k groups, then: computes the centroid, assigns the data points to the nearest centroid and repeats until an optimal point is found. However, this may be a local optimal point, not global. The main strength of K-means is that it is efficient O(tkn). The main weaknesses are that it often terminates at a local optimal point, it is only applicable to continuous n-dimensional space, you need to specify k, it is sensitive to outliers, not good with non-convex shapes, and is sensitive to the seed point. K-medoids (PAM): is more complex, and therefore less efficient. Instead of taking the mean, it takes a center data point, partitions the data, tests a different non-medoid point, if it reduces the SSE, it reassign the medoid. K-medoids works well for small data sets and is less sensitive to outliers, however it is not efficient for large data sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Illustrate the strength and weakness of these schemes in comparison with a hierarchical clustering scheme (e.g., AGNES)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hierarchical methods divides the data into a tree of clusters. Strengths: it does not require K as an input, it is generally efficient for smaller sets, and it can find clusters of arbitrary shapes. The major weaknesses are that the iterations cannot be undone and does not always scale well because each decision of merge or split needs to examine and evaluate many objects or clusters. Variations of these methods such as BIRCH overcome these two weaknesses, but BIRCH only handles numeric data. The partitioning methods described above main strengths vs. this method are ease, efficiency, and the ability to reverse iterations while relative weaknesses are tendency to terminate at a local optimal point, applicability to continuous n-dimensional space, a need to specify k, and difficulty with non-convex shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
